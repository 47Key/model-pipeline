import re
import pandas as pd
import tensorflow as tf
from tensorflow.keras.preprocessing.sequence import pad_sequences
import flask
from flask import (
	Flask,
	request
)

app = Flask(__name__)
app.config["DEBUG"] = False

# Load the model
model = tf.keras.models.load_model("./BILSTM")

# Load the tokenizer parameters from a config
with open('./tokenizer.json', 'r', encoding='utf-8') as f:
    tokenizer_json = f.read()
    
# Rebuild the tokenizer from the config
tokenizer = tf.keras.preprocessing.text.tokenizer_from_json(tokenizer_json)

# Initialize the dictionary for converting NOC code into number from 1 - N (N being the number of unique NOC codes, roughly 400+)
occupation_codes = {
    '11': 1, '12': 2, '13': 3, '14': 4, '15': 5, '16': 6, '111': 7, '112': 8, '113': 9, '114': 10, '121': 11, '122': 12, '124': 13, '125': 14, '131': 15, '132': 16, '211': 17, '212': 18, '213': 19, '311': 20, '411': 21, '412': 22, '413': 23, '414': 24, '421': 25, '422': 26, '423': 27, '431': 28, '432': 29, '433': 30, '511': 31, '512': 32, '513': 33, '601': 34, '621': 35, '631': 36, '632': 37, '651': 38, '711': 39, '712': 40, '714': 41, '731': 42, '811': 43, '821': 44, '822': 45, '823': 46, '911': 47, '912': 48, '1111': 49, '1112': 50, '1113': 51, '1114': 52, '1121': 53, '1122': 54, '1123': 55, '1211': 56, '1212': 57, '1213': 58, '1214': 59, '1215': 60, '1221': 61, '1222': 62, '1223': 63, '1224': 64, '1225': 65, '1226': 66, '1227': 67, '1228': 68, '1241': 69, '1242': 70, '1243': 71, '1251': 72, '1252': 73, '1253': 74, '1254': 75, '1311': 76, '1312': 77, '1313': 78, '1314': 79, '1315': 80, '1411': 81, '1414': 82, '1415': 83, '1416': 84, '1422': 85, '1423': 86, '1431': 87, '1432': 88, '1434': 89, '1435': 90, '1451': 91, '1452': 92, '1454': 93, '1511': 94, '1512': 95, '1513': 96, '1521': 97, '1522': 98, '1523': 99, '1524': 100, '1525': 101, '1526': 102, '2111': 103, '2112': 104, '2113': 105, '2114': 106, '2115': 107, '2121': 108, '2122': 109, '2123': 110, '2131': 111, '2132': 112, '2133': 113, '2134': 114, '2141': 115, '2142': 116, '2143': 117, '2144': 118, '2145': 119, '2146': 120, '2147': 121, '2148': 122, '2151': 123, '2152': 124, '2153': 125, '2154': 126, '2161': 127, '2171': 128, '2172': 129, '2173': 130, '2174': 131, '2175': 132, '2211': 133, '2212': 134, '2221': 135, '2222': 136, '2223': 137, '2224': 138, '2225': 139, '2231': 140, '2232': 141, '2233': 142, '2234': 143, '2241': 144, '2242': 145, '2243': 146, '2244': 147, '2251': 148, '2252': 149, '2253': 150, '2254': 151, '2255': 152, '2261': 153, '2262': 154, '2263': 155, '2264': 156, '2271': 157, '2272': 158, '2273': 159, '2274': 160, '2275': 161, '2281': 162, '2282': 163, '2283': 164, '3011': 165, '3012': 166, '3111': 167, '3112': 168, '3113': 169, '3114': 170, '3121': 171, '3122': 172, '3124': 173, '3125': 174, '3131': 175, '3132': 176, '3141': 177, '3142': 178, '3143': 179, '3144': 180, '3211': 181, '3212': 182, '3213': 183, '3214': 184, '3215': 185, '3216': 186, '3217': 187, '3219': 188, '3221': 189, '3222': 190, '3223': 191, '3231': 192, '3232': 193, '3233': 194, '3234': 195, '3236': 196, '3237': 197, '3411': 198, '3413': 199, '3414': 200, '4011': 201, '4012': 202, '4021': 203, '4031': 204, '4032': 205, '4033': 206, '4111': 207, '4112': 208, '4151': 209, '4152': 210, '4153': 211, '4154': 212, '4155': 213, '4156': 214, '4161': 215, '4162': 216, '4163': 217, '4164': 218, '4165': 219, '4166': 220, '4167': 221, '4168': 222, '4169': 223, '4211': 224, '4212': 225, '4214': 226, '4215': 227, '4216': 228, '4217': 229, '4311': 230, '4312': 231, '4313': 232, '4411': 233, '4412': 234, '4413': 235, '4421': 236, '4422': 237, '4423': 238, '5111': 239, '5112': 240, '5113': 241, '5121': 242, '5122': 243, '5123': 244, '5125': 245, '5131': 246, '5132': 247, '5133': 248, '5134': 249, '5135': 250, '5136': 251, '5211': 252, '5212': 253, '5221': 254, '5222': 255, '5223': 256, '5224': 257, '5225': 258, '5226': 259, '5227': 260, '5231': 261, '5232': 262, '5241': 263, '5242': 264, '5243': 265, '5244': 266, '5245': 267, '5251': 268, '5252': 269, '5253': 270, '5254': 271, '6211': 272, '6221': 273, '6222': 274, '6231': 275, '6232': 276, '6235': 277, '6311': 278, '6312': 279, '6313': 280, '6314': 281, '6315': 282, '6316': 283, '6321': 284, '6322': 285, '6331': 286, '6332': 287, '6341': 288, '6342': 289, '6343': 290, '6344': 291, '6345': 292, '6346': 293, '6411': 294, '6421': 295, '6511': 296, '6512': 297, '6513': 298, '6521': 299, '6522': 300, '6523': 301, '6524': 302, '6525': 303, '6531': 304, '6532': 305, '6533': 306, '6541': 307, '6551': 308, '6552': 309, '6561': 310, '6562': 311, '6563': 312, '6564': 313, '6611': 314, '6621': 315, '6622': 316, '6623': 317, '6711': 318, '6721': 319, '6722': 320, '6731': 321, '6732': 322, '6733': 323, '6741': 324, '6742': 325, '7201': 326, '7202': 327, '7203': 328, '7204': 329, '7205': 330, '7231': 331, '7232': 332, '7233': 333, '7234': 334, '7235': 335, '7236': 336, '7237': 337, '7241': 338, '7242': 339, '7243': 340, '7244': 341, '7245': 342, '7246': 343, '7247': 344, '7251': 345, '7252': 346, '7253': 347, '7271': 348, '7272': 349, '7281': 350, '7282': 351, '7283': 352, '7284': 353, '7291': 354, '7292': 355, '7293': 356, '7294': 357, '7295': 358, '7301': 359, '7302': 360, '7303': 361, '7304': 362, '7305': 363, '7311': 364, '7312': 365, '7313': 366, '7314': 367, '7315': 368, '7316': 369, '7318': 370, '7321': 371, '7322': 372, '7331': 373, '7332': 374, '7333': 375, '7334': 376, '7335': 377, '7361': 378, '7362': 379, '7371': 380, '7372': 381, '7373': 382, '7381': 383, '7384': 384, '7441': 385, '7442': 386, '7444': 387, '7445': 388, '7451': 389, '7452': 390, '7511': 391, '7512': 392, '7513': 393, '7514': 394, '7521': 395, '7522': 396, '7531': 397, '7532': 398, '7533': 399, '7534': 400, '7535': 401, '7611': 402, '7612': 403, '7621': 404, '7622': 405, '8211': 406, '8221': 407, '8222': 408, '8231': 409, '8232': 410, '8241': 411, '8252': 412, '8255': 413, '8261': 414, '8262': 415, '8411': 416, '8412': 417, '8421': 418, '8422': 419, '8431': 420, '8432': 421, '8441': 422, '8442': 423, '8611': 424, '8612': 425, '8613': 426, '8614': 427, '8615': 428, '8616': 429, '9211': 430, '9212': 431, '9213': 432, '9214': 433, '9215': 434, '9217': 435, '9221': 436, '9222': 437, '9223': 438, '9224': 439, '9226': 440, '9227': 441, '9231': 442, '9232': 443, '9235': 444, '9241': 445, '9243': 446, '9411': 447, '9412': 448, '9413': 449, '9414': 450, '9415': 451, '9416': 452, '9417': 453, '9418': 454, '9421': 455, '9422': 456, '9423': 457, '9431': 458, '9432': 459, '9433': 460, '9434': 461, '9435': 462, '9436': 463, '9437': 464, '9441': 465, '9442': 466, '9445': 467, '9446': 468, '9447': 469, '9461': 470, '9462': 471, '9463': 472, '9465': 473, '9471': 474, '9472': 475, '9473': 476, '9474': 477, '9521': 478, '9522': 479, '9523': 480, '9524': 481, '9525': 482, '9526': 483, '9527': 484, '9531': 485, '9532': 486, '9533': 487, '9534': 488, '9535': 489, '9536': 490, '9537': 491, '9611': 492, '9612': 493, '9613': 494, '9614': 495, '9615': 496, '9616': 497, '9617': 498, '9618': 499, '9619': 500
}

def initial_clean_text(text):
    # Remove spaces pre/post
    text = str(text).strip()
    # convert all words to lowercase
    text = str(text).lower()
    # Remove any characters that are not letters
    text = re.sub('[^a-zA-Z]+', ' ', text)
    # strip any whitespace before and after string
    text = text.strip()
    return text

# Function to retrieve the key in the dicitionary parameter, specified by n
def get_occ_key(dictionary, n=0):
  if n == 0:
    raise IndexError("No Dictionary Values Equal to 0")
  else:
    index = n-1
  for i, key in enumerate(dictionary.keys()):
    if i == index:
      return key
  raise IndexError("Dictionary Index is out of Range")

# Main Prediction Function
def predict_fn(texts):
    df = pd.DataFrame({
        'job_info': texts
    })
    
    # Clean the text
    df['job_info'] = df['job_info'].apply(lambda x: initial_clean_text(x))
    
    # Convert the text to token sequences
    token = tokenizer.texts_to_sequences(df['job_info'])
    token = pad_sequences(token, padding='post', maxlen=900)
    
    # Predict the top 3 occupations
    predictions = model.predict(token)
    top_values, top_indices = tf.math.top_k(predictions, k=3)
    noc_codes = []
    for i in range(len(top_indices)):
        top_codes = top_indices[i].numpy()
        predicted1 = get_occ_key(occupation_codes, top_codes[0])
        predicted2 = get_occ_key(occupation_codes, top_codes[1])
        predicted3 = get_occ_key(occupation_codes, top_codes[2])
        noc_codes.append([predicted1, predicted2, predicted3])
        
    return noc_codes

@app.route('/predict', methods=['POST'])
def predict():
    args = request.json
    data = args['data']
    if type(data) == str:
      data = [data]
    return predict_fn(data)

app.run(host="0.0.0.0")

